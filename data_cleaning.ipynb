{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d327cf-4323-48c1-8583-184b3fcb93b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.functions import asc, col, isnan, when, count, median, udf, concat, month, year, substring, lit\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import GBTClassifier, OneVsRest\n",
    "from pyspark.ml import Pipeline\n",
    "import os\n",
    "import pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe265f6-bab5-4c95-9d0d-042def8a922b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/02/21 07:39:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 53404)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/local/lib/python3.9/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/local/lib/python3.9/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/local/lib/python3.9/socketserver.py\", line 747, in __init__\n",
      "    self.handle()\n",
      "  File \"/usr/local/lib/python3.9/site-packages/pyspark/accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/pyspark/accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "  File \"/usr/local/lib/python3.9/site-packages/pyspark/accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "conf = SparkConf() \\\n",
    "    .setAppName(\"data_cleaning\") \\\n",
    "    .set(\"spark.driver.memory\", \"15g\")\\\n",
    "    .set(\"spark.executor.cores\",\"8\") \\\n",
    "    .set(\"spark.sql.execution.arrow.pyspark.enabled\",\"true\")\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0508394-cbf9-4a48-b975-50dde502144b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[fecha_dato: date, ncodpers: double, ind_empleado: string, pais_residencia: string, sexo: string, age: string, fecha_alta: date, ind_nuevo: string, antiguedad: string, indrel: string, ult_fec_cli_1t: date, indrel_1mes: string, tiprel_1mes: string, indresi: string, indext: string, conyuemp: string, canal_entrada: string, indfall: string, tipodom: string, cod_prov: string, nomprov: string, ind_actividad_cliente: string, renta: double, segmento: string, ind_ahor_fin_ult1: int, ind_aval_fin_ult1: int, ind_cco_fin_ult1: int, ind_cder_fin_ult1: int, ind_cno_fin_ult1: int, ind_ctju_fin_ult1: int, ind_ctma_fin_ult1: int, ind_ctop_fin_ult1: int, ind_ctpp_fin_ult1: int, ind_deco_fin_ult1: int, ind_deme_fin_ult1: int, ind_dela_fin_ult1: int, ind_ecue_fin_ult1: int, ind_fond_fin_ult1: int, ind_hip_fin_ult1: int, ind_plan_fin_ult1: int, ind_pres_fin_ult1: int, ind_reca_fin_ult1: int, ind_tjcr_fin_ult1: int, ind_valo_fin_ult1: int, ind_viv_fin_ult1: int, ind_nomina_ult1: string, ind_nom_pens_ult1: string, ind_recibo_ult1: int]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file_path =\"/workspace/data.csv\"\n",
    "df = spark.read.csv(csv_file_path, header=True, inferSchema=True)\n",
    "df.orderBy(asc(\"fecha_dato\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0beb8b49-ecd7-4b20-a49b-4d70d7d384b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Fill NA with overall mean\n",
    "mean_age_18_to_30 = df.filter((F.col(\"age\") >= 18) & (F.col(\"age\") <= 30)).select(F.mean(\"age\")).collect()[0][0]\n",
    "mean_age_30_to_100 = df.filter((F.col(\"age\") >= 30) & (F.col(\"age\") <= 100)).select(F.mean(\"age\")).collect()[0][0]\n",
    "overall_mean_age = df.select(F.mean(\"age\")).collect()[0][0]\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"age\",\n",
    "    F.when(F.col(\"age\") < 18, mean_age_18_to_30)\n",
    "     .when(F.col(\"age\") > 100, mean_age_30_to_100)\n",
    "     .otherwise(F.col(\"age\"))\n",
    ")\n",
    "\n",
    "df = df.fillna({\"age\": overall_mean_age})\n",
    "df = df.withColumn(\"age\", F.col(\"age\").cast(\"int\"))\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"age\",\n",
    "    F.when(F.col(\"age\").isNull(), overall_mean_age).otherwise(F.col(\"age\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b1492a6-7533-4887-8575-f85a76055047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Filling missing falue with the most common status\n",
    "df = df.fillna({\"ind_nuevo\": 1})\n",
    "df = df.fillna({\"indrel\": 1})\n",
    "df = df.fillna({\"ind_nomina_ult1\": 0})\n",
    "df = df.fillna({\"ind_nom_pens_ult1\": 0})\n",
    "df = df.fillna({\"indfall\": \"N\"})\n",
    "df = df.fillna({\"tiprel_1mes\": \"A\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdff52d8-9af3-4f27-b014-eaffef0c9ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to cast\n",
    "columns_to_cast = [\n",
    "    \"ind_nuevo\",\n",
    "    \"indrel\",\n",
    "    \"ind_ahor_fin_ult1\",\n",
    "    \"ind_aval_fin_ult1\",\n",
    "    \"ind_cco_fin_ult1\",\n",
    "    \"ind_cder_fin_ult1\",\n",
    "    \"ind_cno_fin_ult1\",\n",
    "    \"ind_ctju_fin_ult1\",\n",
    "    \"ind_ctma_fin_ult1\",\n",
    "    \"ind_ctop_fin_ult1\",\n",
    "    \"ind_ctpp_fin_ult1\",\n",
    "    \"ind_deco_fin_ult1\",\n",
    "    \"ind_deme_fin_ult1\",\n",
    "    \"ind_dela_fin_ult1\",\n",
    "    \"ind_ecue_fin_ult1\",\n",
    "    \"ind_fond_fin_ult1\",\n",
    "    \"ind_hip_fin_ult1\",\n",
    "    \"ind_plan_fin_ult1\",\n",
    "    \"ind_pres_fin_ult1\",\n",
    "    \"ind_reca_fin_ult1\",\n",
    "    \"ind_tjcr_fin_ult1\",\n",
    "    \"ind_valo_fin_ult1\",\n",
    "    \"ind_viv_fin_ult1\",\n",
    "    \"ind_nomina_ult1\",\n",
    "    \"ind_nom_pens_ult1\",\n",
    "    \"ind_recibo_ult1\",\n",
    "    \"renta\"\n",
    "]\n",
    "\n",
    "# Cast each column to IntegerType\n",
    "for column in columns_to_cast:\n",
    "    df = df.withColumn(column, df[column].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ba62a41-f4d6-4023-9f5d-058c56ef60f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/21 07:40:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/02/21 07:40:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/02/21 07:40:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/02/21 07:41:03 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/02/21 07:41:03 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "window_spec = Window.orderBy(F.col(\"fecha_alta\"))\n",
    "dates = df.select(\n",
    "    \"fecha_alta\",\n",
    "    F.row_number().over(window_spec).alias(\"index\")\n",
    ")\n",
    "total_rows = dates.count()\n",
    "median_index = (total_rows // 2) + 1 \n",
    "median_value = dates.filter(F.col(\"index\") == median_index).select(\"fecha_alta\").collect()[0][0]\n",
    "df = df.withColumn(\n",
    "    \"fecha_alta\",\n",
    "    F.when(F.col(\"fecha_alta\").isNull(), median_value).otherwise(F.col(\"fecha_alta\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbb275f4-8552-4ee3-8481-2496694140fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace null values with median\n",
    "median_value = df.select(F.median(\"ind_actividad_cliente\")).collect()[0][0]\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"ind_actividad_cliente\",\n",
    "    F.when(F.col(\"ind_actividad_cliente\").isNull(), median_value).otherwise(F.col(\"ind_actividad_cliente\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "081203e9-3f00-408c-a3a6-76e05dc42476",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.na.drop(subset=[\"nomprov\"]) \n",
    "\n",
    "grouped = df.groupBy(\"nomprov\").agg(median(\"renta\").alias(\"renta_median\"))\n",
    "\n",
    "df = df.join(grouped, \"nomprov\", \"left\")\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"renta\",\n",
    "    F.when(F.col(\"renta\").isNull(), col(\"renta_median\")).otherwise(F.col(\"renta\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aee0f0a4-e50c-432c-a4c8-6732df90083d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\n",
    "    \"conyuemp\",\n",
    "    F.when(F.col(\"conyuemp\").isNull(), -1).otherwise(F.col(\"conyuemp\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3abc50a4-edc6-4eaf-a742-b8b9ea9631d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dict_Null = {col:df.filter(df[col].isNull()).count() for col in df.columns}\n",
    "# Dict_Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "530c8b33-f888-46f2-86f6-22696b4be4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "canal_dict = {'KAI': 35,'KBG': 17,'KGU': 149,'KDE': 47,'KAJ': 41,'KCG': 59,\n",
    " 'KHM': 12,'KAL': 74,'KFH': 140,'KCT': 112,'KBJ': 133,'KBL': 88,'KHQ': 157,'KFB': 146,'KFV': 48,'KFC': 4,\n",
    " 'KCK': 52,'KAN': 110,'KES': 68,'KCB': 78,'KBS': 118,'KDP': 103,'KDD': 113,'KBX': 116,'KCM': 82,\n",
    " 'KAE': 30,'KAB': 28,'KFG': 27,'KDA': 63,'KBV': 100,'KBD': 109,'KBW': 114,'KGN': 11,\n",
    " 'KCP': 129,'KAK': 51,'KAR': 32,'KHK': 10,'KDS': 124,'KEY': 93,'KFU': 36,'KBY': 111,\n",
    " 'KEK': 145,'KCX': 120,'KDQ': 80,'K00': 50,'KCC': 29,'KCN': 81,'KDZ': 99,'KDR': 56,\n",
    " 'KBE': 119,'KFN': 42,'KEC': 66,'KDM': 130,'KBP': 121,'KAU': 142,'KDU': 79,\n",
    " 'KCH': 84,'KHF': 19,'KCR': 153,'KBH': 90,'KEA': 89,'KEM': 155,'KGY': 44,'KBM': 135,\n",
    " 'KEW': 98,'KDB': 117,'KHD': 2,'RED': 8,'KBN': 122,'KDY': 61,'KDI': 150,'KEU': 72,\n",
    " 'KCA': 73,'KAH': 31,'KAO': 94,'KAZ': 7,'004': 83,'KEJ': 95,'KBQ': 62,'KEZ': 108,\n",
    " 'KCI': 65,'KGW': 147,'KFJ': 33,'KCF': 105,'KFT': 92,'KED': 143,'KAT': 5,'KDL': 158,\n",
    " 'KFA': 3,'KCO': 104,'KEO': 96,'KBZ': 67,'KHA': 22,'KDX': 69,'KDO': 60,'KAF': 23,'KAW': 76,\n",
    " 'KAG': 26,'KAM': 107,'KEL': 125,'KEH': 15,'KAQ': 37,'KFD': 25,'KEQ': 138,'KEN': 137,\n",
    " 'KFS': 38,'KBB': 131,'KCE': 86,'KAP': 46,'KAC': 57,'KBO': 64,'KHR': 161,'KFF': 45,\n",
    " 'KEE': 152,'KHL': 0,'007': 71,'KDG': 126,'025': 159,'KGX': 24,'KEI': 97,'KBF': 102,\n",
    " 'KEG': 136,'KFP': 40,'KDF': 127,'KCJ': 156,'KFR': 144,'KDW': 132,-1: 6,'KAD': 16,\n",
    " 'KBU': 55,'KCU': 115,'KAA': 39,'KEF': 128,'KAY': 54,'KGC': 18,'KAV': 139,'KDN': 151,\n",
    " 'KCV': 106,'KCL': 53,'013': 49,'KDV': 91,'KFE': 148,'KCQ': 154,'KDH': 14,'KHN': 21,\n",
    " 'KDT': 58,'KBR': 101,'KEB': 123,'KAS': 70,'KCD': 85,'KFL': 34,'KCS': 77,'KHO': 13,\n",
    " 'KEV': 87,'KHE': 1,'KHC': 9,'KFK': 20,'KDC': 75,'KFM': 141,'KHP': 160,'KHS': 162,\n",
    " 'KFI': 134,'KGV': 43}\n",
    "\n",
    "\n",
    "pais_dict = {'LV': 102,'CA': 2,'GB': 9,'EC': 19,'BY': 64,'ML': 104,'MT': 118,\n",
    " 'LU': 59,'GR': 39,'NI': 33,'BZ': 113,'QA': 58,'DE': 10,'AU': 63,'IN': 31,\n",
    " 'GN': 98,'KE': 65,'HN': 22,'JM': 116,'SV': 53,'TH': 79,'IE': 5,'TN': 85,\n",
    " 'PH': 91,'ET': 54,'AR': 13,'KR': 87,'GA': 45,'FR': 8,'SG': 66,'LB': 81,\n",
    " 'MA': 38,'NZ': 93,'SK': 69,'CN': 28,'GI': 96,'PY': 51,'SA': 56,'PL': 30,\n",
    " 'PE': 20,'GE': 78,'HR': 67,'CD': 112,'MM': 94,'MR': 48,'NG': 83,'HU': 106,\n",
    " 'AO': 71,'NL': 7,'GM': 110,'DJ': 115,'ZA': 75,'OM': 100,'LT': 103,'MZ': 27,\n",
    " 'VE': 14,'EE': 52,'CF': 109,'CL': 4,'SL': 97,'DO': 11,'PT': 26,'ES': 0,\n",
    " 'CZ': 36,'AD': 35,'RO': 41,'TW': 29,'BA': 61,'IS': 107,'AT': 6,'ZW': 114,\n",
    " 'TR': 70,'CO': 21,'PK': 84,'SE': 24,'AL': 25,'CU': 72,'UY': 77,'EG': 74,'CR': 32,\n",
    " 'GQ': 73,'MK': 105,'KW': 92,'GT': 44,'CM': 55,'SN': 47,'KZ': 111,'DK': 76,\n",
    " 'LY': 108,'AE': 37,'PA': 60,'UA': 49,'GW': 99,'TG': 86,'MX': 16,'KH': 95,\n",
    " 'FI': 23,'NO': 46,'IT': 18,'GH': 88, 'JP': 82,'RU': 43,'PR': 40,'RS': 89,\n",
    " 'DZ': 80,'MD': 68,-1: 1,'BG': 50,'CI': 57,'IL': 42,'VN': 90,'CH': 3,'US': 15,'HK': 34,\n",
    " 'CG': 101,'BO': 62,'BR': 17,'BE': 12,'BM': 117}\n",
    "\n",
    "emp_dict = {'N':0,-1:-1,'A':1,'B':2,'F':3,'S':4}\n",
    "indfall_dict = {'N':0,-1:-1,'S':1}\n",
    "sexo_dict = {'V':0,'H':1,-1:-1}\n",
    "tiprel_dict = {'A':0,-1:-1,'I':1,'P':2,'N':3,'R':4}\n",
    "indresi_dict = {'N':0,-1:-1,'S':1}\n",
    "indext_dict = {'N':0,-1:-1,'S':1}\n",
    "conyuemp_dict = {'N':0,-1:-1,'S':1}\n",
    "segmento_dict = {-1:-1,'01 - TOP':1,'02 - PARTICULARES':2,'03 - UNIVERSITARIO':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16508500-8374-4fff-b388-a0ec38aae0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def map_emp_status(status):\n",
    "#     return emp_dict.get(status, -1)  # Use .get() to handle missing keys\n",
    "\n",
    "# # Create a UDF from the Python function\n",
    "# emp_udf = udf(map_emp_status, IntegerType())\n",
    "\n",
    "# # Apply the UDF to the DataFrame\n",
    "# spark_df = df.withColumn(\"ind_empleado\", emp_udf(col(\"ind_empleado\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdbcf84a-fb58-44ad-a698-3faf9cf5dab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34b0408a-b463-4fae-be4a-3eb42945ce22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mapping_udf(mapping_dict):\n",
    "    def map_value(value):\n",
    "        return mapping_dict.get(value, -1)  # Default to -1 if not found\n",
    "    return udf(map_value, IntegerType())\n",
    "\n",
    "canal_udf = create_mapping_udf(canal_dict)\n",
    "pais_udf = create_mapping_udf(pais_dict)\n",
    "indfall_udf = create_mapping_udf(indfall_dict)\n",
    "sexo_udf = create_mapping_udf(sexo_dict)\n",
    "tiprel_udf = create_mapping_udf(tiprel_dict)\n",
    "indresi_udf = create_mapping_udf(indresi_dict)\n",
    "indext_udf = create_mapping_udf(indext_dict)\n",
    "conyuemp_udf = create_mapping_udf(conyuemp_dict)\n",
    "segmento_udf = create_mapping_udf(segmento_dict)\n",
    "emp_udf = create_mapping_udf(emp_dict)\n",
    "\n",
    "def apply_udfs(spark_df):\n",
    "    spark_df = spark_df.withColumn(\"canal_entrada\", canal_udf(col(\"canal_entrada\")).cast(IntegerType()))\n",
    "    spark_df = spark_df.withColumn(\"pais_residencia\", pais_udf(col(\"pais_residencia\")).cast(IntegerType()))\n",
    "    spark_df = spark_df.withColumn(\"indfall\", indfall_udf(col(\"indfall\")).cast(IntegerType()))\n",
    "    spark_df = spark_df.withColumn(\"sexo\", sexo_udf(col(\"sexo\")).cast(IntegerType()))\n",
    "    spark_df = spark_df.withColumn(\"tiprel_1mes\", tiprel_udf(col(\"tiprel_1mes\")).cast(IntegerType()))\n",
    "    spark_df = spark_df.withColumn(\"indresi\", indresi_udf(col(\"indresi\")).cast(IntegerType()))\n",
    "    spark_df = spark_df.withColumn(\"indext\", indext_udf(col(\"indext\")).cast(IntegerType()))\n",
    "    spark_df = spark_df.withColumn(\"conyuemp\", conyuemp_udf(col(\"conyuemp\")).cast(IntegerType()))\n",
    "    spark_df = spark_df.withColumn(\"segmento\", segmento_udf(col(\"segmento\")).cast(IntegerType()))\n",
    "    spark_df = spark_df.withColumn(\"ind_empleado\", segmento_udf(col(\"ind_empleado\")).cast(IntegerType()))\n",
    "    \n",
    "    return spark_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53e2cc2e-7fed-4a98-934f-019c5ddf5476",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = apply_udfs(spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7460556d-9396-4cc2-abec-fd15f526a4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark_df.fillna({\"ult_fec_cli_1t\" : '2020-01-01'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "108bc651-962a-4763-ab69-0108d396aa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark_df.withColumn(\"fecha_dato_month\", substring(\"fecha_dato\", 6, 2).cast(IntegerType()))\n",
    "spark_df = spark_df.withColumn(\"fecha_dato_year\", (substring(\"fecha_dato\", 1, 4).cast(IntegerType()) - 2015))\n",
    "spark_df = spark_df.withColumn(\"month_int\", (col(\"fecha_dato_month\") + 12 * col(\"fecha_dato_year\")).cast(IntegerType()))\n",
    "spark_df = spark_df.withColumn(\"fecha_dato_day\", substring(\"fecha_dato\", 9, 2).cast(IntegerType()))\n",
    "for col_name in [\"fecha_dato_month\", \"fecha_dato_year\", \"month_int\", \"fecha_dato_day\"]:\n",
    "    spark_df = spark_df.withColumn(col_name, \\\n",
    "                        when(col(col_name).isNull(), lit(-1)) \\\n",
    "                        .otherwise(col(col_name)))\n",
    "\n",
    "# Drop the original column\n",
    "spark_df = spark_df.drop(\"fecha_dato\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9922750-e2a5-4218-ad1d-d84b3a603775",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark_df.withColumn(\"ult_fec_cli_1t_month\", substring(\"ult_fec_cli_1t\", 6, 2).cast(IntegerType()))\n",
    "spark_df = spark_df.withColumn(\"ult_fec_cli_1t_year\", (substring(\"ult_fec_cli_1t\", 1, 4).cast(IntegerType()) - 2015))\n",
    "spark_df = spark_df.withColumn(\"ult_fec_cli_1t_day\", substring(\"ult_fec_cli_1t\", 9, 2).cast(IntegerType()))\n",
    "spark_df = spark_df.withColumn(\"ult_fec_cli_1t_month_int\", (col(\"ult_fec_cli_1t_month\") + 12 * col(\"ult_fec_cli_1t_year\")))\n",
    "    #Check if any value is null, then fill with -1\n",
    "for col_name in [\"ult_fec_cli_1t_month\", \"ult_fec_cli_1t_year\", \"ult_fec_cli_1t_day\", \"ult_fec_cli_1t_month_int\"]:\n",
    "    spark_df = spark_df.withColumn(col_name, \\\n",
    "                       when(col(col_name).isNull(), -1) \\\n",
    "                       .otherwise(col(col_name)))\n",
    "spark_df = spark_df.drop(\"ult_fec_cli_1t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f3d2b53-ad62-44fc-b2ca-a012df7ebafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark_df.withColumn(\"fecha_alta_month\", substring(\"fecha_alta\", 6, 2).cast(IntegerType()))\n",
    "spark_df = spark_df.withColumn(\"fecha_alta_year\", (substring(\"fecha_alta\", 1, 4).cast(IntegerType()) - 1995))\n",
    "spark_df = spark_df.withColumn(\"fecha_alta_day\", substring(\"fecha_alta\", 9, 2).cast(IntegerType()))\n",
    "spark_df = spark_df.withColumn(\"fecha_alta_month_int\", (col(\"fecha_alta_month\") + 12 * col(\"fecha_alta_year\")).cast(IntegerType()))\n",
    "spark_df = spark_df.withColumn(\"fecha_alta_day_int\", (col(\"fecha_alta_day\") + 30 * col(\"fecha_alta_month\") + 365 * col(\"fecha_alta_year\")).cast(IntegerType()))\n",
    "\n",
    "# Drop the original column\n",
    "spark_df = spark_df.drop(\"fecha_alta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b0d71ca-666d-4fd0-86ba-2159174959c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in [\"fecha_dato_month\", \"fecha_dato_year\", \"month_int\"]:\n",
    "    spark_df = spark_df.withColumn(col_name, \\\n",
    "                        when(col(col_name).isNull(), -1) \\\n",
    "                        .otherwise(col(col_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fba50de-0b17-4104-899c-ced6d01c837b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark_df.fillna({\"ind_nomina_ult1\": -1})\n",
    "spark_df = spark_df.fillna({\"ind_nom_pens_ult1\": -1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "863ad9cf-7183-4da3-993a-1157cdc5aa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark_df.withColumn(\"indrel_1mes\",when(col(\"indrel_1mes\") == \"P\", -2).otherwise(col(\"indrel_1mes\")))\n",
    "spark_df = spark_df.fillna({\"indrel_1mes\": -1})\n",
    "spark_df = spark_df.withColumn(\"ind_actividad_cliente\", when(col(\"ind_actividad_cliente\").isNull(), lit(-1)).otherwise(col(\"ind_actividad_cliente\").cast(IntegerType())))\n",
    "spark_df = spark_df.withColumn(\"indrel_1mes\", col(\"indrel_1mes\").cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff83be58-b956-4e03-a4f2-d15090addf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Filling missing falue with the most common status\n",
    "spark_df = spark_df.fillna({\"ind_nuevo\": 1})\n",
    "spark_df = spark_df.fillna({\"indrel\": 1})\n",
    "spark_df = spark_df.fillna({\"ind_nomina_ult1\": 0})\n",
    "spark_df = spark_df.fillna({\"ind_nom_pens_ult1\": 0})\n",
    "spark_df = spark_df.fillna({\"indfall\": \"N\"})\n",
    "spark_df = spark_df.fillna({\"tiprel_1mes\": \"A\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50eafa79-dbf5-4dfc-8301-d2c16ac50941",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark_df.withColumn(\"tipodom\", when(col(\"tipodom\").isNull(), lit(-1)).otherwise(col(\"tipodom\").cast(IntegerType())))\n",
    "spark_df = spark_df.withColumn(\"cod_prov\", when(col(\"cod_prov\").isNull(), lit(-1)).otherwise(col(\"cod_prov\").cast(IntegerType())))\n",
    "spark_df = spark_df.withColumn(\"antiguedad\",when(col(\"antiguedad\").isNull(), lit(-1)).otherwise(col(\"antiguedad\")))\n",
    "spark_df = spark_df.withColumn(\"antiguedad\", col(\"antiguedad\").cast(IntegerType()))\n",
    "spark_df = spark_df.drop(\"nomprov\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fac2acb9-5651-4619-a18e-86363418fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict_Null = {col:spark_df.filter(spark_df[col] == -1).count() for col in spark_df.columns}\n",
    "# Dict_Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eccaacbd-19c1-40d9-a804-39ca919afc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of NULLs\n",
    "# age_null = {df.filter(df['age'].isNull()).count()}\n",
    "# age_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c0bd797-896d-47dd-9e40-d4a186c333af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{70}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_null = {spark_df.filter(spark_df['sexo'] == -1 ).count()}\n",
    "age_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55865aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = [ \"ind_ahor_fin_ult1\",\n",
    "    \"ind_aval_fin_ult1\",\n",
    "    \"ind_cco_fin_ult1\",\n",
    "    \"ind_cder_fin_ult1\",\n",
    "    \"ind_cno_fin_ult1\",\n",
    "    \"ind_ctju_fin_ult1\",\n",
    "    \"ind_ctma_fin_ult1\",\n",
    "    \"ind_ctop_fin_ult1\",\n",
    "    \"ind_ctpp_fin_ult1\",\n",
    "    \"ind_deco_fin_ult1\",\n",
    "    \"ind_deme_fin_ult1\",\n",
    "    \"ind_dela_fin_ult1\",\n",
    "    \"ind_ecue_fin_ult1\",\n",
    "    \"ind_fond_fin_ult1\",\n",
    "    \"ind_hip_fin_ult1\",\n",
    "    \"ind_plan_fin_ult1\",\n",
    "    \"ind_pres_fin_ult1\",\n",
    "    \"ind_reca_fin_ult1\",\n",
    "    \"ind_tjcr_fin_ult1\",\n",
    "    \"ind_valo_fin_ult1\",\n",
    "    \"ind_viv_fin_ult1\",\n",
    "    \"ind_nomina_ult1\",\n",
    "    \"ind_nom_pens_ult1\",\n",
    "    \"ind_recibo_ult1\"]\n",
    "\n",
    "w = Window.partitionBy(\"ncodpers\").orderBy(\"month_int\")\n",
    "\n",
    "lag_months =[1,2,3]\n",
    "for lag in lag_months:\n",
    "    for col in target_cols:\n",
    "        spark_df = spark_df.withColumn(f\"lag_{lag}_{col}\", F.lag(F.col(col),lag).over(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f659d297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ncodpers: double (nullable = true)\n",
      " |-- ind_empleado: integer (nullable = true)\n",
      " |-- pais_residencia: integer (nullable = true)\n",
      " |-- sexo: integer (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- ind_nuevo: integer (nullable = false)\n",
      " |-- antiguedad: integer (nullable = true)\n",
      " |-- indrel: integer (nullable = false)\n",
      " |-- indrel_1mes: integer (nullable = true)\n",
      " |-- tiprel_1mes: integer (nullable = true)\n",
      " |-- indresi: integer (nullable = true)\n",
      " |-- indext: integer (nullable = true)\n",
      " |-- conyuemp: integer (nullable = true)\n",
      " |-- canal_entrada: integer (nullable = true)\n",
      " |-- indfall: integer (nullable = true)\n",
      " |-- tipodom: integer (nullable = true)\n",
      " |-- cod_prov: integer (nullable = true)\n",
      " |-- ind_actividad_cliente: integer (nullable = true)\n",
      " |-- renta: double (nullable = true)\n",
      " |-- segmento: integer (nullable = true)\n",
      " |-- ind_ahor_fin_ult1: integer (nullable = true)\n",
      " |-- ind_aval_fin_ult1: integer (nullable = true)\n",
      " |-- ind_cco_fin_ult1: integer (nullable = true)\n",
      " |-- ind_cder_fin_ult1: integer (nullable = true)\n",
      " |-- ind_cno_fin_ult1: integer (nullable = true)\n",
      " |-- ind_ctju_fin_ult1: integer (nullable = true)\n",
      " |-- ind_ctma_fin_ult1: integer (nullable = true)\n",
      " |-- ind_ctop_fin_ult1: integer (nullable = true)\n",
      " |-- ind_ctpp_fin_ult1: integer (nullable = true)\n",
      " |-- ind_deco_fin_ult1: integer (nullable = true)\n",
      " |-- ind_deme_fin_ult1: integer (nullable = true)\n",
      " |-- ind_dela_fin_ult1: integer (nullable = true)\n",
      " |-- ind_ecue_fin_ult1: integer (nullable = true)\n",
      " |-- ind_fond_fin_ult1: integer (nullable = true)\n",
      " |-- ind_hip_fin_ult1: integer (nullable = true)\n",
      " |-- ind_plan_fin_ult1: integer (nullable = true)\n",
      " |-- ind_pres_fin_ult1: integer (nullable = true)\n",
      " |-- ind_reca_fin_ult1: integer (nullable = true)\n",
      " |-- ind_tjcr_fin_ult1: integer (nullable = true)\n",
      " |-- ind_valo_fin_ult1: integer (nullable = true)\n",
      " |-- ind_viv_fin_ult1: integer (nullable = true)\n",
      " |-- ind_nomina_ult1: integer (nullable = false)\n",
      " |-- ind_nom_pens_ult1: integer (nullable = false)\n",
      " |-- ind_recibo_ult1: integer (nullable = true)\n",
      " |-- renta_median: double (nullable = true)\n",
      " |-- fecha_dato_month: integer (nullable = true)\n",
      " |-- fecha_dato_year: integer (nullable = true)\n",
      " |-- month_int: integer (nullable = true)\n",
      " |-- fecha_dato_day: integer (nullable = true)\n",
      " |-- ult_fec_cli_1t_month: integer (nullable = true)\n",
      " |-- ult_fec_cli_1t_year: integer (nullable = true)\n",
      " |-- ult_fec_cli_1t_day: integer (nullable = true)\n",
      " |-- ult_fec_cli_1t_month_int: integer (nullable = true)\n",
      " |-- fecha_alta_month: integer (nullable = true)\n",
      " |-- fecha_alta_year: integer (nullable = true)\n",
      " |-- fecha_alta_day: integer (nullable = true)\n",
      " |-- fecha_alta_month_int: integer (nullable = true)\n",
      " |-- fecha_alta_day_int: integer (nullable = true)\n",
      " |-- lag_1_ind_ahor_fin_ult1: integer (nullable = true)\n",
      " |-- lag_1_ind_aval_fin_ult1: integer (nullable = true)\n",
      " |-- lag_1_ind_cco_fin_ult1: integer (nullable = true)\n",
      " |-- lag_1_ind_cder_fin_ult1: integer (nullable = true)\n",
      " |-- lag_1_ind_cno_fin_ult1: integer (nullable = true)\n",
      " |-- lag_1_ind_ctju_fin_ult1: integer (nullable = true)\n",
      " |-- lag_1_ind_ctma_fin_ult1: integer (nullable = true)\n",
      " |-- lag_1_ind_ctop_fin_ult1: integer (nullable = true)\n",
      " |-- lag_1_ind_ctpp_fin_ult1: integer (nullable = true)\n",
      " |-- lag_1_ind_deco_fin_ult1: integer (nullable = true)\n",
      " |-- lag_1_ind_deme_fin_ult1: integer (nullable = true)\n",
      " |-- lag_1_ind_dela_fin_ult1: integer (nullable = true)\n",
      " |-- lag_1_ind_ecue_fin_ult1: integer (nullable = true)\n",
      " |-- lag_1_ind_fond_fin_ult1: integer (nullable = true)\n",
      " |-- lag_1_ind_hip_fin_ult1: integer (nullable = true)\n",
      " |-- lag_1_ind_plan_fin_ult1: integer (nullable = true)\n",
      " |-- lag_1_ind_pres_fin_ult1: integer (nullable = true)\n",
      " |-- lag_1_ind_reca_fin_ult1: integer (nullable = true)\n",
      " |-- lag_1_ind_tjcr_fin_ult1: integer (nullable = true)\n",
      " |-- lag_1_ind_valo_fin_ult1: integer (nullable = true)\n",
      " |-- lag_1_ind_viv_fin_ult1: integer (nullable = true)\n",
      " |-- lag_1_ind_nomina_ult1: integer (nullable = true)\n",
      " |-- lag_1_ind_nom_pens_ult1: integer (nullable = true)\n",
      " |-- lag_1_ind_recibo_ult1: integer (nullable = true)\n",
      " |-- lag_2_ind_ahor_fin_ult1: integer (nullable = true)\n",
      " |-- lag_2_ind_aval_fin_ult1: integer (nullable = true)\n",
      " |-- lag_2_ind_cco_fin_ult1: integer (nullable = true)\n",
      " |-- lag_2_ind_cder_fin_ult1: integer (nullable = true)\n",
      " |-- lag_2_ind_cno_fin_ult1: integer (nullable = true)\n",
      " |-- lag_2_ind_ctju_fin_ult1: integer (nullable = true)\n",
      " |-- lag_2_ind_ctma_fin_ult1: integer (nullable = true)\n",
      " |-- lag_2_ind_ctop_fin_ult1: integer (nullable = true)\n",
      " |-- lag_2_ind_ctpp_fin_ult1: integer (nullable = true)\n",
      " |-- lag_2_ind_deco_fin_ult1: integer (nullable = true)\n",
      " |-- lag_2_ind_deme_fin_ult1: integer (nullable = true)\n",
      " |-- lag_2_ind_dela_fin_ult1: integer (nullable = true)\n",
      " |-- lag_2_ind_ecue_fin_ult1: integer (nullable = true)\n",
      " |-- lag_2_ind_fond_fin_ult1: integer (nullable = true)\n",
      " |-- lag_2_ind_hip_fin_ult1: integer (nullable = true)\n",
      " |-- lag_2_ind_plan_fin_ult1: integer (nullable = true)\n",
      " |-- lag_2_ind_pres_fin_ult1: integer (nullable = true)\n",
      " |-- lag_2_ind_reca_fin_ult1: integer (nullable = true)\n",
      " |-- lag_2_ind_tjcr_fin_ult1: integer (nullable = true)\n",
      " |-- lag_2_ind_valo_fin_ult1: integer (nullable = true)\n",
      " |-- lag_2_ind_viv_fin_ult1: integer (nullable = true)\n",
      " |-- lag_2_ind_nomina_ult1: integer (nullable = true)\n",
      " |-- lag_2_ind_nom_pens_ult1: integer (nullable = true)\n",
      " |-- lag_2_ind_recibo_ult1: integer (nullable = true)\n",
      " |-- lag_3_ind_ahor_fin_ult1: integer (nullable = true)\n",
      " |-- lag_3_ind_aval_fin_ult1: integer (nullable = true)\n",
      " |-- lag_3_ind_cco_fin_ult1: integer (nullable = true)\n",
      " |-- lag_3_ind_cder_fin_ult1: integer (nullable = true)\n",
      " |-- lag_3_ind_cno_fin_ult1: integer (nullable = true)\n",
      " |-- lag_3_ind_ctju_fin_ult1: integer (nullable = true)\n",
      " |-- lag_3_ind_ctma_fin_ult1: integer (nullable = true)\n",
      " |-- lag_3_ind_ctop_fin_ult1: integer (nullable = true)\n",
      " |-- lag_3_ind_ctpp_fin_ult1: integer (nullable = true)\n",
      " |-- lag_3_ind_deco_fin_ult1: integer (nullable = true)\n",
      " |-- lag_3_ind_deme_fin_ult1: integer (nullable = true)\n",
      " |-- lag_3_ind_dela_fin_ult1: integer (nullable = true)\n",
      " |-- lag_3_ind_ecue_fin_ult1: integer (nullable = true)\n",
      " |-- lag_3_ind_fond_fin_ult1: integer (nullable = true)\n",
      " |-- lag_3_ind_hip_fin_ult1: integer (nullable = true)\n",
      " |-- lag_3_ind_plan_fin_ult1: integer (nullable = true)\n",
      " |-- lag_3_ind_pres_fin_ult1: integer (nullable = true)\n",
      " |-- lag_3_ind_reca_fin_ult1: integer (nullable = true)\n",
      " |-- lag_3_ind_tjcr_fin_ult1: integer (nullable = true)\n",
      " |-- lag_3_ind_valo_fin_ult1: integer (nullable = true)\n",
      " |-- lag_3_ind_viv_fin_ult1: integer (nullable = true)\n",
      " |-- lag_3_ind_nomina_ult1: integer (nullable = true)\n",
      " |-- lag_3_ind_nom_pens_ult1: integer (nullable = true)\n",
      " |-- lag_3_ind_recibo_ult1: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bacd9a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/21 07:42:15 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark_df.write.parquet(\"train_test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2bab23be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"ncodpers\", \"ind_empleado\", \"pais_residencia\", \"sexo\", \"age\", \"ind_nuevo\", \"antiguedad\", \"indrel\", \"indrel_1mes\", \"tiprel_1mes\", \"indresi\", \"indext\", \"conyuemp\", \"canal_entrada\", \"indfall\", \"tipodom\", \"cod_prov\", \"ind_actividad_cliente\", \"renta\", \"segmento\", \"ind_ahor_fin_ult1\", \"ind_aval_fin_ult1\", \"ind_cco_fin_ult1\", \"ind_cder_fin_ult1\", \"ind_cno_fin_ult1\", \"ind_ctju_fin_ult1\", \"ind_ctma_fin_ult1\", \"ind_ctop_fin_ult1\", \"ind_ctpp_fin_ult1\", \"ind_deco_fin_ult1\", \"ind_deme_fin_ult1\", \"ind_dela_fin_ult1\", \"ind_ecue_fin_ult1\", \"ind_fond_fin_ult1\", \"ind_hip_fin_ult1\", \"ind_plan_fin_ult1\", \"ind_pres_fin_ult1\", \"ind_reca_fin_ult1\", \"ind_tjcr_fin_ult1\", \"ind_valo_fin_ult1\", \"ind_viv_fin_ult1\", \"ind_nomina_ult1\", \"ind_nom_pens_ult1\", \"ind_recibo_ult1\", \"renta_median\", \"fecha_dato_month\", \"fecha_dato_year\", \"month_int\", \"fecha_dato_day\", \"ult_fec_cli_1t_month\", \"ult_fec_cli_1t_year\", \"ult_fec_cli_1t_day\", \"ult_fec_cli_1t_month_int\", \"fecha_alta_month\", \"fecha_alta_year\", \"fecha_alta_day\", \"fecha_alta_month_int\", \"fecha_alta_day_int\", \"lag_1_ind_ahor_fin_ult1\", \"lag_1_ind_aval_fin_ult1\", \"lag_1_ind_cco_fin_ult1\", \"lag_1_ind_cder_fin_ult1\", \"lag_1_ind_cno_fin_ult1\", \"lag_1_ind_ctju_fin_ult1\", \"lag_1_ind_ctma_fin_ult1\", \"lag_1_ind_ctop_fin_ult1\", \"lag_1_ind_ctpp_fin_ult1\", \"lag_1_ind_deco_fin_ult1\", \"lag_1_ind_deme_fin_ult1\", \"lag_1_ind_dela_fin_ult1\", \"lag_1_ind_ecue_fin_ult1\", \"lag_1_ind_fond_fin_ult1\", \"lag_1_ind_hip_fin_ult1\", \"lag_1_ind_plan_fin_ult1\", \"lag_1_ind_pres_fin_ult1\", \"lag_1_ind_reca_fin_ult1\", \"lag_1_ind_tjcr_fin_ult1\", \"lag_1_ind_valo_fin_ult1\", \"lag_1_ind_viv_fin_ult1\", \"lag_1_ind_nomina_ult1\", \"lag_1_ind_nom_pens_ult1\", \"lag_1_ind_recibo_ult1\", \"lag_2_ind_ahor_fin_ult1\", \"lag_2_ind_aval_fin_ult1\", \"lag_2_ind_cco_fin_ult1\", \"lag_2_ind_cder_fin_ult1\", \"lag_2_ind_cno_fin_ult1\", \"lag_2_ind_ctju_fin_ult1\", \"lag_2_ind_ctma_fin_ult1\", \"lag_2_ind_ctop_fin_ult1\", \"lag_2_ind_ctpp_fin_ult1\", \"lag_2_ind_deco_fin_ult1\", \"lag_2_ind_deme_fin_ult1\", \"lag_2_ind_dela_fin_ult1\", \"lag_2_ind_ecue_fin_ult1\", \"lag_2_ind_fond_fin_ult1\", \"lag_2_ind_hip_fin_ult1\", \"lag_2_ind_plan_fin_ult1\", \"lag_2_ind_pres_fin_ult1\", \"lag_2_ind_reca_fin_ult1\", \"lag_2_ind_tjcr_fin_ult1\", \"lag_2_ind_valo_fin_ult1\", \"lag_2_ind_viv_fin_ult1\", \"lag_2_ind_nomina_ult1\", \"lag_2_ind_nom_pens_ult1\", \"lag_2_ind_recibo_ult1\", \"lag_3_ind_ahor_fin_ult1\", \"lag_3_ind_aval_fin_ult1\", \"lag_3_ind_cco_fin_ult1\", \"lag_3_ind_cder_fin_ult1\", \"lag_3_ind_cno_fin_ult1\", \"lag_3_ind_ctju_fin_ult1\", \"lag_3_ind_ctma_fin_ult1\", \"lag_3_ind_ctop_fin_ult1\", \"lag_3_ind_ctpp_fin_ult1\", \"lag_3_ind_deco_fin_ult1\", \"lag_3_ind_deme_fin_ult1\", \"lag_3_ind_dela_fin_ult1\", \"lag_3_ind_ecue_fin_ult1\", \"lag_3_ind_fond_fin_ult1\", \"lag_3_ind_hip_fin_ult1\", \"lag_3_ind_plan_fin_ult1\", \"lag_3_ind_pres_fin_ult1\", \"lag_3_ind_reca_fin_ult1\", \"lag_3_ind_tjcr_fin_ult1\", \"lag_3_ind_valo_fin_ult1\", \"lag_3_ind_viv_fin_ult1\", \"lag_3_ind_nomina_ult1\", \"lag_3_ind_nom_pens_ult1\", \"lag_3_ind_recibo_ult1\"\n"
     ]
    }
   ],
   "source": [
    "# Python\n",
    "print(\", \".join(f'\"{col}\"' for col in spark_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1f0c577",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Window' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Define a window partitioned by customer and ordered by date\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m w \u001b[38;5;241m=\u001b[39m \u001b[43mWindow\u001b[49m\u001b[38;5;241m.\u001b[39mpartitionBy(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mncodpers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39morderBy(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfecha_dato\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Compute the previous month value to calculate the gap\u001b[39;00m\n\u001b[1;32m      5\u001b[0m spark_df \u001b[38;5;241m=\u001b[39m spark_df\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprev_month\u001b[39m\u001b[38;5;124m\"\u001b[39m, F\u001b[38;5;241m.\u001b[39mlag(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmonth_int\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mover(w))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Window' is not defined"
     ]
    }
   ],
   "source": [
    "# Define a window partitioned by customer and ordered by date\n",
    "w = Window.partitionBy(\"ncodpers\").orderBy(\"fecha_dato\")\n",
    "\n",
    "# Compute the previous month value to calculate the gap\n",
    "spark_df = spark_df.withColumn(\"prev_month\", F.lag(\"month_int\").over(w))\n",
    "spark_df = spark_df.withColumn(\"month_diff\", \n",
    "                   F.when(F.col(\"prev_month\").isNotNull(), \n",
    "                          F.col(\"month_int\") - F.col(\"prev_month\"))\n",
    "                    .otherwise(0))\n",
    "\n",
    "# Flag a gap if the difference is not equal to 1 (and ignore the first record)\n",
    "spark_df = spark_df.withColumn(\"gap_flag\", \n",
    "                   F.when((F.col(\"month_diff\") != 1) & F.col(\"prev_month\").isNotNull(), 1)\n",
    "                    .otherwise(0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
