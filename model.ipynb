{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pyarrow.compute as pc\n",
    "import pyarrow as pa\n",
    "import xgboost as xgb\n",
    "import torch\n",
    "import gc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Giải Phóng Bộ Nhớ GPU (Nếu Có)\n",
    "\n",
    "Đoạn mã này định nghĩa một hàm `clear_gpu_memory()` và sau đó gọi hàm đó để giải phóng bộ nhớ GPU (Graphics Processing Unit) nếu GPU có sẵn. Điều này rất quan trọng trong các ứng dụng sử dụng GPU, đặc biệt là các ứng dụng liên quan đến deep learning, để tránh tình trạng hết bộ nhớ (out-of-memory error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_gpu_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "clear_gpu_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thiết Lập Đường Dẫn Tệp Parquet, Danh Sách Sản Phẩm và Các Lagged Feature\n",
    "\n",
    "Đoạn mã này thực hiện các bước sau:\n",
    "\n",
    "1.  **Định nghĩa đường dẫn đến tệp Parquet:** Xác định vị trí của tệp Parquet chứa dữ liệu huấn luyện và kiểm tra.\n",
    "2.  **Đọc tệp Parquet:** Sử dụng thư viện `pyarrow.parquet` để đọc tệp Parquet vào một biến có tên `table`. Tệp Parquet là một định dạng lưu trữ cột hiệu quả, thường được sử dụng cho các tập dữ liệu lớn.\n",
    "3.  **Định nghĩa danh sách sản phẩm:** Tạo một danh sách các tên cột, mỗi cột đại diện cho một sản phẩm khác nhau. Các tên cột này có vẻ như là các biến chỉ báo cho sự hiện diện của một sản phẩm cụ thể cho một khách hàng.\n",
    "4.  **Tạo danh sách các Lagged Feature:** Tạo một danh sách các tên Lagged Feature. Lagged Feature là giá trị của một biến tại một thời điểm trước đó. Trong trường hợp này, nó tạo tên cho các Lagged Feature cho mỗi sản phẩm với độ trễ từ 1 đến 6 tháng.\n",
    "\n",
    "**Các Bước Chi Tiết:**\n",
    "\n",
    "*   **`parquet_file = \"/kaggle/input/traintestparquet/train_test.parquet\"`:** Gán đường dẫn đến tệp Parquet cho biến `parquet_file`.\n",
    "*   **`table = pq.read_table(parquet_file)`:** Sử dụng hàm `pq.read_table()` từ thư viện `pyarrow.parquet` để đọc tệp Parquet vào một biến có tên `table`.\n",
    "*   **`products = [...]`:** Tạo một danh sách các chuỗi, mỗi chuỗi đại diện cho tên của một sản phẩm. Các sản phẩm này dường như là các sản phẩm tài chính.\n",
    "*   **`lag_months = [1, 2, 3, 4, 5, 6]`:** Tạo một danh sách các số nguyên, mỗi số nguyên đại diện cho một độ trễ (lag) tính bằng tháng.\n",
    "*   **`lagged_features = [f\"lag_{lag}_{prod}\" for lag in lag_months for prod in products]`:** Sử dụng list comprehension để tạo một danh sách các tên Lagged Feature.  Đầu ra của đoạn code này là một danh sách các chuỗi, mỗi chuỗi có định dạng \"lag\\_\\[lag]\\_\\[prod]\", trong đó \\[lag] là một giá trị từ `lag_months` và \\[prod] là một giá trị từ `products`.  Ví dụ: \"lag\\_1\\_ind\\_ahor\\_fin\\_ult1\", \"lag\\_2\\_ind\\_ahor\\_fin\\_ult1\", ..., \"lag\\_6\\_ind\\_recibo\\_ult1\".\n",
    "\n",
    "**Chú Thích Thuật Ngữ:**\n",
    "\n",
    "*   **Parquet:** Một định dạng lưu trữ cột hiệu quả, thường được sử dụng cho các tập dữ liệu lớn.\n",
    "*   **Lagged Feature:** Một đặc trưng được tạo bằng cách lấy giá trị của một biến tại một thời điểm trước đó.  Chúng thường được sử dụng trong các mô hình dự đoán chuỗi thời gian.\n",
    "*   **List Comprehension:** Một cách ngắn gọn để tạo một danh sách mới từ một hoặc nhiều danh sách khác."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_file = \"/kaggle/input/traintestparquet/train_test.parquet\"\n",
    "table = pq.read_table(parquet_file)\n",
    "\n",
    "\n",
    "products = [\n",
    "    \"ind_ahor_fin_ult1\", \"ind_aval_fin_ult1\", \"ind_cco_fin_ult1\",\n",
    "    \"ind_cder_fin_ult1\", \"ind_cno_fin_ult1\", \"ind_ctju_fin_ult1\",\n",
    "    \"ind_ctma_fin_ult1\", \"ind_ctop_fin_ult1\", \"ind_ctpp_fin_ult1\",\n",
    "    \"ind_deco_fin_ult1\", \"ind_deme_fin_ult1\", \"ind_dela_fin_ult1\",\n",
    "    \"ind_ecue_fin_ult1\", \"ind_fond_fin_ult1\", \"ind_hip_fin_ult1\",\n",
    "    \"ind_plan_fin_ult1\", \"ind_pres_fin_ult1\", \"ind_reca_fin_ult1\",\n",
    "    \"ind_tjcr_fin_ult1\", \"ind_valo_fin_ult1\", \"ind_viv_fin_ult1\",\n",
    "    \"ind_nomina_ult1\", \"ind_nom_pens_ult1\", \"ind_recibo_ult1\"\n",
    "]\n",
    "\n",
    "lag_months = [1, 2, 3, 4, 5, 6]\n",
    "lagged_features = [f\"lag_{lag}_{prod}\" for lag in lag_months for prod in products]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chia Tập Dữ Liệu Thành Train, Validation và Test\n",
    "\n",
    "Đoạn mã này sử dụng thư viện `pyarrow` để chia tập dữ liệu `table` thành ba tập con: tập huấn luyện (train), tập kiểm định (validation), và tập kiểm tra (test) dựa trên giá trị của cột \"month_int\".\n",
    "\n",
    "**Các Bước:**\n",
    "\n",
    "1.  **Tạo Bộ Lọc (Filter):**\n",
    "    *   `train_filter = pc.less(table[\"month_int\"], 15)`: Tạo bộ lọc cho tập huấn luyện. Bản ghi được chọn vào tập huấn luyện nếu giá trị trong cột \"month_int\" nhỏ hơn 15.\n",
    "    *   `val_filter = pc.equal(table[\"month_int\"], 15)`: Tạo bộ lọc cho tập kiểm định. Bản ghi được chọn vào tập kiểm định nếu giá trị trong cột \"month_int\" bằng 15.\n",
    "    *   `test_filter = pc.equal(table[\"month_int\"], 16)`: Tạo bộ lọc cho tập kiểm tra. Bản ghi được chọn vào tập kiểm tra nếu giá trị trong cột \"month_int\" bằng 16.\n",
    "\n",
    "2.  **Áp Dụng Bộ Lọc:**\n",
    "    *   `train_table = table.filter(train_filter)`: Áp dụng bộ lọc `train_filter` để tạo tập huấn luyện `train_table`.\n",
    "    *   `val_table = table.filter(val_filter)`: Áp dụng bộ lọc `val_filter` để tạo tập kiểm định `val_table`.\n",
    "    *   `test_table = table.filter(test_filter)`: Áp dụng bộ lọc `test_filter` để tạo tập kiểm tra `test_table`.\n",
    "\n",
    "**Ý Nghĩa:**\n",
    "\n",
    "Đoạn mã chia dữ liệu theo thời gian, giả sử \"month_int\" đại diện cho tháng dưới dạng số nguyên. Dữ liệu từ các tháng trước tháng 15 được sử dụng để huấn luyện mô hình, dữ liệu tháng 15 được sử dụng để kiểm định mô hình (điều chỉnh các siêu tham số), và dữ liệu tháng 16 được sử dụng để đánh giá hiệu năng cuối cùng của mô hình.\n",
    "\n",
    "**Chú Thích Thuật Ngữ:**\n",
    "\n",
    "*   **pc (pyarrow.compute):** Mô-đun tính toán của thư viện `pyarrow`.\n",
    "*   **Filter:** Một điều kiện được sử dụng để chọn một tập hợp con của dữ liệu.\n",
    "*   **Validation Set:** Tập dữ liệu được sử dụng để điều chỉnh các siêu tham số của mô hình.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 3. Chia train, val, test\n",
    "\n",
    "train_filter = pc.less(table[\"month_int\"], 15)\n",
    "val_filter = pc.equal(table[\"month_int\"], 15)\n",
    "test_filter  = pc.equal(table[\"month_int\"], 16)\n",
    "\n",
    "train_table = table.filter(train_filter)\n",
    "val_table  = table.filter(val_filter)\n",
    "test_table  = table.filter(test_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chuẩn Bị Dữ Liệu Huấn Luyện\n",
    "\n",
    "Đoạn mã này chuẩn bị dữ liệu huấn luyện cho mô hình dự đoán sản phẩm mới.\n",
    "\n",
    "**Các Bước:**\n",
    "\n",
    "1.  **Xác định khách hàng mới sử dụng sản phẩm:** Lọc ra những khách hàng chuyển từ không sử dụng sang sử dụng sản phẩm trong tháng hiện tại.\n",
    "2.  **Tạo ma trận đặc trưng:** Sử dụng các lagged feature (giá trị sản phẩm ở các tháng trước) cho những khách hàng này.\n",
    "3.  **Tạo label:** Gán label cho mỗi khách hàng, tương ứng với sản phẩm mới mà họ sử dụng.\n",
    "4.  **Kết hợp dữ liệu:** Ghép nối dữ liệu từ các sản phẩm khác nhau để tạo thành tập huấn luyện cuối cùng.\n",
    "\n",
    "**Chú Thích Thuật Ngữ:**\n",
    "\n",
    "*   **Lagged Feature:** Giá trị của một biến tại một thời điểm trong quá khứ.\n",
    "*   **Label:** Nhãn, giá trị mục tiêu mà mô hình cần dự đoán.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 4. Prepare training data\n",
    "\n",
    "training_features_list = []\n",
    "training_labels_list = []\n",
    "\n",
    "for product_index, product in enumerate(products):\n",
    "    current_month_indicators = train_table.column(product).to_numpy()\n",
    "    previous_month_indicators = train_table.column(f\"lag_1_{product}\").to_numpy()\n",
    "\n",
    "    newly_added_product_mask = (current_month_indicators == 1) & (previous_month_indicators == 0)\n",
    "    if np.sum(newly_added_product_mask) == 0:\n",
    "        continue\n",
    "\n",
    "    lagged_feature_arrays = []\n",
    "    for feature in lagged_features:\n",
    "        feature_column = train_table.column(feature).to_numpy()\n",
    "        lagged_feature_arrays.append(feature_column[newly_added_product_mask].reshape(-1, 1))\n",
    "\n",
    "    feature_matrix = np.hstack(lagged_feature_arrays)\n",
    "    training_features_list.append(feature_matrix)\n",
    "\n",
    "    training_labels_list.append(np.full(feature_matrix.shape[0], product_index, dtype=np.int8))\n",
    "\n",
    "if len(training_features_list) == 0:\n",
    "    raise ValueError(\"No training data found. Check the data and filters.\")\n",
    "\n",
    "training_features = np.vstack(training_features_list)\n",
    "training_labels = np.concatenate(training_labels_list)\n",
    "\n",
    "print(\"Training samples:\", training_features.shape[0])\n",
    "print(\"Number of features:\", training_features.shape[1])\n",
    "print(\"Training labels distribution:\", {i: int(np.sum(training_labels==i)) for i in np.unique(training_labels)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chuẩn Bị Dữ Liệu Kiểm Định\n",
    "\n",
    "Đoạn mã này chuẩn bị dữ liệu kiểm định, tương tự như quá trình chuẩn bị dữ liệu huấn luyện.\n",
    "\n",
    "**Các Bước:**\n",
    "\n",
    "1.  **Xác định khách hàng mới sử dụng sản phẩm:** Lọc ra những khách hàng chuyển từ không sử dụng sang sử dụng sản phẩm trong tháng hiện tại, sử dụng dữ liệu từ `val_table`.\n",
    "2.  **Tạo Feature Matrix:** Sử dụng các lagged feature cho những khách hàng này.\n",
    "3.  **Tạo label:** Gán label cho mỗi khách hàng, tương ứng với sản phẩm mới mà họ sử dụng.\n",
    "4.  **Kết hợp dữ liệu:** Ghép nối dữ liệu từ các sản phẩm khác nhau để tạo thành tập kiểm định cuối cùng.\n",
    "\n",
    "**Chú Thích Thuật Ngữ:**\n",
    "\n",
    "*   **Lagged Feature:** Giá trị của một biến tại một thời điểm trong quá khứ.\n",
    "*   **Feature Matrix:** Ma trận chứa các đặc trưng cho mỗi mẫu dữ liệu.\n",
    "*   **Label:** Nhãn, giá trị mục tiêu mà mô hình cần dự đoán.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 4.5. Prepare validation data\n",
    "\n",
    "validation_features_list = []\n",
    "validation_labels_list = []\n",
    "\n",
    "for product_index, product in enumerate(products):\n",
    "    current_month_indicators = val_table.column(product).to_numpy()\n",
    "    previous_month_indicators = val_table.column(f\"lag_1_{product}\").to_numpy()\n",
    "\n",
    "    newly_added_product_mask = (current_month_indicators == 1) & (previous_month_indicators == 0)\n",
    "    if np.sum(newly_added_product_mask) == 0:\n",
    "        continue\n",
    "\n",
    "    lagged_feature_arrays = []\n",
    "    for feature in lagged_features:\n",
    "        feature_column = val_table.column(feature).to_numpy()\n",
    "        lagged_feature_arrays.append(feature_column[newly_added_product_mask].reshape(-1, 1))\n",
    "\n",
    "    feature_matrix = np.hstack(lagged_feature_arrays)\n",
    "    validation_features_list.append(feature_matrix)\n",
    "\n",
    "    validation_labels_list.append(np.full(feature_matrix.shape[0], product_index, dtype=np.int8))\n",
    "\n",
    "if len(validation_features_list) == 0:\n",
    "    print(\"Warning: No validation data found for new product additions. Validation set might be empty.\")\n",
    "    validation_features = np.empty((0, len(lagged_features)))\n",
    "    validation_labels = np.empty(0, dtype=np.int8)\n",
    "else:\n",
    "    validation_features = np.vstack(validation_features_list)\n",
    "    validation_labels = np.concatenate(validation_labels_list)\n",
    "\n",
    "print(\"Validation samples:\", validation_features.shape[0])\n",
    "print(\"Number of features:\", validation_features.shape[1])\n",
    "print(\"Validation labels distribution:\", {i: int(np.sum(validation_labels==i)) for i in np.unique(validation_labels)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chuẩn Bị Dữ Liệu Kiểm Tra\n",
    "\n",
    "Đoạn mã này chuẩn bị dữ liệu kiểm tra để đưa vào mô hình.\n",
    "\n",
    "**Các Bước:**\n",
    "\n",
    "1.  **Tạo ma trận đặc trưng:** Trích xuất các lagged feature từ `test_table` và ghép thành ma trận `test_features`.\n",
    "2.  **Lấy mã khách hàng:** Trích xuất mã khách hàng (`ncodpers`) từ `test_table` để sử dụng sau này (ví dụ: tạo tệp nộp bài).\n",
    "\n",
    "**Chú Thích Thuật Ngữ:**\n",
    "\n",
    "*   **Lagged Feature:** Giá trị của một biến tại một thời điểm trong quá khứ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 5. Prepare test data\n",
    "\n",
    "test_feature_arrays = []\n",
    "for feature in lagged_features:\n",
    "    arr = test_table.column(feature).to_numpy()\n",
    "    test_feature_arrays.append(arr.reshape(-1, 1))\n",
    "test_features = np.hstack(test_feature_arrays)\n",
    "\n",
    "ncodpers = test_table.column(\"ncodpers\").to_pylist()\n",
    "\n",
    "print(\"Test samples:\", test_features.shape[0])\n",
    "print(\"Test feature shape:\", test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tạo XGBoost DMatrix và Thiết Lập Tham Số\n",
    "\n",
    "Đoạn mã này chuẩn bị dữ liệu và cấu hình mô hình XGBoost.\n",
    "\n",
    "**Các Bước:**\n",
    "\n",
    "1.  **Tạo DMatrix:** Chuyển đổi dữ liệu huấn luyện, kiểm định và kiểm tra thành định dạng `DMatrix` mà XGBoost sử dụng, bao gồm `feature` và `label` (nếu có).\n",
    "2.  **Thiết lập tham số:** Xác định các tham số để cấu hình mô hình XGBoost, bao gồm mục tiêu, tốc độ học, độ sâu tối đa của cây, và các tham số liên quan đến việc lấy mẫu cột.\n",
    "\n",
    "**Chú Thích Thuật Ngữ:**\n",
    "\n",
    "*   **DMatrix:** Cấu trúc dữ liệu được tối ưu hóa cho XGBoost.\n",
    "*   **XGBoost:** Thuật toán gradient boosting được sử dụng để xây dựng mô hình.\n",
    "*   **Feature:** Đặc trưng.\n",
    "*   **Label:** Nhãn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ------------------------------------------------------------------------\n",
    "# 6. Build XGBoost DMatrix objects\n",
    "\n",
    "dtrain = xgb.DMatrix(training_features, label=training_labels, feature_names=lagged_features)\n",
    "dval = xgb.DMatrix(validation_features, label=validation_labels, feature_names=lagged_features) # Created dval\n",
    "dtest  = xgb.DMatrix(test_features, feature_names=lagged_features)\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 7. Set XGBoost parameters (multi:softprob for multiclass)\n",
    "param = {\n",
    "    \"objective\": \"multi:softprob\",\n",
    "    \"eta\": 0.1,\n",
    "    \"min_child_weight\": 10,\n",
    "    \"max_depth\": 8,\n",
    "    \"silent\": 1,\n",
    "    \"eval_metric\": \"mlogloss\",\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"colsample_bylevel\": 0.9,\n",
    "    \"num_class\": len(products),\n",
    "    \"device\": \"cuda\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huấn Luyện Mô Hình XGBoost\n",
    "\n",
    "Đoạn mã này thực hiện quá trình huấn luyện mô hình XGBoost.\n",
    "\n",
    "**Các Bước:**\n",
    "\n",
    "1.  **Thiết lập các tham số huấn luyện:**\n",
    "    *   `num_boost_round`: Số lượng vòng lặp boosting (số lượng cây được xây dựng).\n",
    "    *   `watchlist`: Danh sách các tập dữ liệu được sử dụng để theo dõi hiệu năng trong quá trình huấn luyện (trong trường hợp này, tập huấn luyện và tập kiểm định).\n",
    "2.  **Huấn luyện mô hình:** Gọi hàm `xgb.train` để huấn luyện mô hình XGBoost với các tham số đã thiết lập, dữ liệu huấn luyện, và watchlist. Sử dụng `early_stopping_rounds` để dừng huấn luyện sớm nếu hiệu năng trên tập kiểm định không cải thiện trong một số vòng lặp nhất định.\n",
    "3.  **In thông tin về độ quan trọng của feature:** Lấy và in ra thông tin về độ quan trọng của các `feature` trong mô hình đã huấn luyện. Các `feature` quan trọng hơn sẽ có điểm số cao hơn.\n",
    "\n",
    "**Chú Thích Thuật Ngữ:**\n",
    "\n",
    "*   **Boosting:** Một kỹ thuật machine learning kết hợp nhiều mô hình yếu để tạo ra một mô hình mạnh hơn.\n",
    "*   **Feature Importance:** Độ quan trọng của một `feature` trong việc dự đoán.\n",
    "*   **Feature:** Đặc trưng.\n",
    "*   **Early Stopping:** Kỹ thuật dừng huấn luyện sớm nếu hiệu năng không cải thiện.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 8. Train the XGBoost model\n",
    "\n",
    "num_boost_round = 1000\n",
    "watchlist = [(dtrain, \"train\"), (dval, \"eval\")]\n",
    "\n",
    "print(\"Training XGBoost model ...\")\n",
    "model = xgb.train(param, dtrain, num_boost_round, evals=watchlist, early_stopping_rounds=20)\n",
    "\n",
    "print(\"\\nFeature Importance:\")\n",
    "feature_importance = model.get_fscore()  \n",
    "for feat, score in sorted(feature_importance.items(), key=lambda item: item[1], reverse=True):\n",
    "    print(f\"{feat}: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dự Đoán Trên Dữ Liệu Kiểm Tra\n",
    "\n",
    "Đoạn mã này sử dụng mô hình XGBoost đã được huấn luyện để dự đoán trên dữ liệu kiểm tra.\n",
    "\n",
    "**Các Bước:**\n",
    "\n",
    "1.  **Dự đoán:** Gọi hàm `model.predict` để tạo ra các dự đoán trên `DMatrix` của dữ liệu kiểm tra (`dtest`).\n",
    "2.  **In hình dạng của kết quả dự đoán:** In ra hình dạng của mảng chứa các dự đoán.\n",
    "\n",
    "**Chú Thích Thuật Ngữ:**\n",
    "\n",
    "*   **DMatrix:** Cấu trúc dữ liệu được tối ưu hóa cho XGBoost.\n",
    "*   **Predict:** Dự đoán, tạo ra các giá trị đầu ra từ mô hình dựa trên dữ liệu đầu vào.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 9. Predict on test data (fixing the AttributeError)\n",
    "\n",
    "preds = model.predict(dtest)\n",
    "print(\"\\nPredictions shape:\", preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Định Nghĩa Hàm Tạo Tệp Submission\n",
    "\n",
    "Đoạn mã này định nghĩa một hàm có tên `make_submission_file` để tạo tệp submission ở định dạng cần thiết cho cuộc thi.\n",
    "\n",
    "**Các Bước:**\n",
    "\n",
    "1.  **Viết header:** Ghi dòng tiêu đề \"ncodpers,added\\_products\" vào tệp submission.\n",
    "2.  **Lặp qua các dự đoán và mã khách hàng:** Với mỗi khách hàng,\n",
    "    *   **Chọn top 7 sản phẩm được dự đoán:** Sắp xếp các sản phẩm theo xác suất dự đoán giảm dần và chọn 7 sản phẩm hàng đầu.\n",
    "    *   **Chuyển đổi chỉ số sản phẩm thành tên sản phẩm:** Tìm tên của từng sản phẩm được dự đoán từ danh sách `products`.\n",
    "    *   **Ghi dòng vào tệp submission:** Ghi mã khách hàng và danh sách các sản phẩm được dự đoán vào tệp submission.\n",
    "\n",
    "**Chú Thích Thuật Ngữ:**\n",
    "\n",
    "*   **Submission:** Tệp chứa các dự đoán của mô hình ở định dạng yêu cầu của cuộc thi hoặc hệ thống đánh giá.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 10. Define submission function\n",
    "\n",
    "import io\n",
    "\n",
    "def make_submission_file(submission_file, predictions, customer_ids, products):\n",
    "    submission_file.write(\"ncodpers,added_products\\n\".encode('utf-8'))\n",
    "    for customer_id, prediction in zip(customer_ids, predictions):\n",
    "        predicted_products_indices = np.argsort(prediction)[::-1][:7]\n",
    "        predicted_product_names = [products[i] for i in predicted_products_indices]\n",
    "        submission_file.write((\"%s,%s\\n\" % (int(customer_id), \" \".join(predicted_product_names))).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Định Nghĩa Hàm MAP@7 và Tạo Submission\n",
    "\n",
    "Đoạn mã này định nghĩa hàm tính MAP@7 (Mean Average Precision at 7) và tạo tệp submission.\n",
    "\n",
    "**Các Bước:**\n",
    "\n",
    "1.  **Định nghĩa hàm tính MAP@7:**\n",
    "    *   Định nghĩa hàm `apk(actual, predicted, k=7, default=0.0)` để tính Average Precision at k (AP@k) cho một khách hàng.\n",
    "    *   Định nghĩa hàm `mapk(actual, predicted, k=7, default=0.0)` để tính Mean Average Precision at k (MAP@k) trên toàn bộ tập dữ liệu. Trong đoạn code này, k được đặt là 7 cho MAP@7.\n",
    "2.  **Tạo tệp submission:**\n",
    "    *   Sử dụng hàm `make_submission_file` (đã định nghĩa trước đó) để tạo tệp submission trong bộ nhớ (sử dụng `io.BytesIO`).\n",
    "3.  **Tính MAP@7 (chỉ để minh họa):**\n",
    "    *   Đọc tệp submission từ bộ nhớ.\n",
    "    *   Trích xuất danh sách các sản phẩm được dự đoán cho mỗi khách hàng từ tệp submission.\n",
    "    *   **Lưu ý quan trọng:** Trong đoạn code này, giá trị \"thực tế\" (actual) được đặt bằng giá trị dự đoán (predicted) để minh họa cách tính MAP@7. **Trong thực tế, bạn cần thay thế giá trị này bằng giá trị thực tế từ tập kiểm định (validation set) để có kết quả đánh giá chính xác.**\n",
    "    *   Tính MAP@7 bằng cách sử dụng hàm `mapk` với danh sách các sản phẩm được dự đoán và danh sách các sản phẩm thực tế (đã được thay thế bằng giá trị dự đoán trong ví dụ này).\n",
    "    *   In ra giá trị MAP@7.\n",
    "\n",
    "**Chú Thích Thuật Ngữ:**\n",
    "\n",
    "*   **MAP@7 (Mean Average Precision at 7):** Một metric đánh giá hiệu năng được sử dụng trong các bài toán gợi ý (recommendation), đo lường độ chính xác của 7 sản phẩm hàng đầu được dự đoán.\n",
    "*   **Submission:** Tệp chứa các dự đoán của mô hình ở định dạng yêu cầu của cuộc thi hoặc hệ thống đánh giá.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 11. Define MAP@7 metric function\n",
    "\n",
    "def apk(actual, predicted, k=7, default=0.0):\n",
    "    \"\"\"\n",
    "    Calculate the average precision at k (AP@k) for a single instance.\n",
    "    \n",
    "    :param actual: List of actual products.\n",
    "    :param predicted: List of predicted products.\n",
    "    :param k: The number of predictions to consider.\n",
    "    :param default: The default value to return if there are no actual products.\n",
    "    :return: The average precision at k.\n",
    "    \"\"\"\n",
    "    if len(predicted) > k:\n",
    "        predicted = predicted[:k]\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "    for i, p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i + 1.0)\n",
    "    if not actual:\n",
    "        return default\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=7, default=0.0):\n",
    "    \"\"\"\n",
    "    Calculate the mean average precision at k (MAP@k) for a set of instances.\n",
    "    \n",
    "    :param actual: List of lists of actual products.\n",
    "    :param predicted: List of lists of predicted products.\n",
    "    :param k: The number of predictions to consider.\n",
    "    :param default: The default value to return if there are no actual products.\n",
    "    :return: The mean average precision at k.\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a, p, k, default) for a, p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ghi Tệp Submission Ra Định Dạng TXT và CSV\n",
    "\n",
    "Đoạn mã này ghi nội dung của tệp submission (đã được tạo trong bộ nhớ) ra hai tệp vật lý: một tệp văn bản (`submission.txt`) và một tệp CSV (`submission.csv`).\n",
    "\n",
    "**Các Bước:**\n",
    "\n",
    "1.  **Lấy nội dung submission:** Lấy nội dung của submission từ `submission_io_buffer` (là một đối tượng `io.BytesIO` chứa nội dung submission ở dạng bytes) và giải mã nó thành chuỗi UTF-8.\n",
    "2.  **Ghi vào tệp TXT:** Mở một tệp mới có tên `submission.txt` ở chế độ ghi (`'w'`) và ghi nội dung submission vào tệp này.\n",
    "3.  **Ghi vào tệp CSV:** Mở một tệp mới có tên `submission.csv` ở chế độ ghi (`'w'`) và ghi nội dung submission vào tệp này.\n",
    "4.  **In thông báo:** In ra thông báo xác nhận rằng tệp submission đã được ghi thành công.\n",
    "\n",
    "**Ý Nghĩa:**\n",
    "\n",
    "Đoạn mã này tạo hai bản sao của tệp submission ở hai định dạng khác nhau. Định dạng CSV thường được yêu cầu bởi các cuộc thi, trong khi định dạng TXT có thể hữu ích để xem và gỡ lỗi nội dung submission.\n",
    "\n",
    "**Chú Thích Thuật Ngữ:**\n",
    "\n",
    "*   **Submission:** Tệp chứa các dự đoán của mô hình ở định dạng yêu cầu của cuộc thi hoặc hệ thống đánh giá.\n",
    "*   **UTF-8:** Một bảng mã ký tự phổ biến được sử dụng để biểu diễn văn bản.\n",
    "*   **CSV (Comma Separated Values):** Một định dạng tệp văn bản đơn giản sử dụng dấu phẩy để phân tách các giá trị.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 13. Write submission to txt and csv files\n",
    "\n",
    "submission_content = submission_io_buffer.getvalue().decode('utf-8')\n",
    "\n",
    "txt_filename = \"submission.txt\"\n",
    "with open(txt_filename, 'w') as txt_file:\n",
    "    txt_file.write(submission_content)\n",
    "print(f\"\\nSubmission written to: {txt_filename}\")\n",
    "\n",
    "csv_filename = \"submission.csv\"\n",
    "with open(csv_filename, 'w') as csv_file:\n",
    "    csv_file.write(submission_content)\n",
    "print(f\"Submission written to: {csv_filename}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
